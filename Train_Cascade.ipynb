{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 90
    },
    "id": "C_MXOtj1jt8g",
    "outputId": "f872ed31-b754-4393-a968-f3e037283f40"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'opencv-haar-classifier-training' already exists and is not an empty directory.\n"
     ]
    }
   ],
   "source": [
    "# We use a repo publicly available to train haar-cascade classifier\n",
    "!git clone https://github.com/mrnugget/opencv-haar-classifier-training.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 145
    },
    "id": "FyNtcQ5Zjzik",
    "outputId": "d449fde6-85f7-4106-d9fd-89f01a7c666e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'EigenFaces'...\n",
      "Updating files:  12% (542/4468)\n",
      "Updating files:  13% (581/4468)\n",
      "Updating files:  14% (626/4468)\n",
      "Updating files:  15% (671/4468)\n",
      "Updating files:  16% (715/4468)\n",
      "Updating files:  17% (760/4468)\n",
      "Updating files:  18% (805/4468)\n",
      "Updating files:  19% (849/4468)\n",
      "Updating files:  20% (894/4468)\n",
      "Updating files:  21% (939/4468)\n",
      "Updating files:  22% (983/4468)\n",
      "Updating files:  23% (1028/4468)\n",
      "Updating files:  24% (1073/4468)\n",
      "Updating files:  25% (1117/4468)\n",
      "Updating files:  25% (1143/4468)\n",
      "Updating files:  26% (1162/4468)\n",
      "Updating files:  27% (1207/4468)\n",
      "Updating files:  27% (1228/4468)\n",
      "Updating files:  28% (1252/4468)\n",
      "Updating files:  29% (1296/4468)\n",
      "Updating files:  30% (1341/4468)\n",
      "Updating files:  31% (1386/4468)\n",
      "Updating files:  32% (1430/4468)\n",
      "Updating files:  33% (1475/4468)\n",
      "Updating files:  34% (1520/4468)\n",
      "Updating files:  35% (1564/4468)\n",
      "Updating files:  36% (1609/4468)\n",
      "Updating files:  37% (1654/4468)\n",
      "Updating files:  38% (1698/4468)\n",
      "Updating files:  39% (1743/4468)\n",
      "Updating files:  40% (1788/4468)\n",
      "Updating files:  41% (1832/4468)\n",
      "Updating files:  42% (1877/4468)\n",
      "Updating files:  43% (1922/4468)\n",
      "Updating files:  44% (1966/4468)\n",
      "Updating files:  45% (2011/4468)\n",
      "Updating files:  45% (2033/4468)\n",
      "Updating files:  46% (2056/4468)\n",
      "Updating files:  47% (2100/4468)\n",
      "Updating files:  48% (2145/4468)\n",
      "Updating files:  49% (2190/4468)\n",
      "Updating files:  49% (2199/4468)\n",
      "Updating files:  50% (2234/4468)\n",
      "Updating files:  50% (2256/4468)\n",
      "Updating files:  51% (2279/4468)\n",
      "Updating files:  51% (2313/4468)\n",
      "Updating files:  52% (2324/4468)\n",
      "Updating files:  52% (2363/4468)\n",
      "Updating files:  53% (2369/4468)\n",
      "Updating files:  54% (2413/4468)\n",
      "Updating files:  55% (2458/4468)\n",
      "Updating files:  55% (2461/4468)\n",
      "Updating files:  56% (2503/4468)\n",
      "Updating files:  57% (2547/4468)\n",
      "Updating files:  57% (2556/4468)\n",
      "Updating files:  58% (2592/4468)\n",
      "Updating files:  58% (2622/4468)\n",
      "Updating files:  59% (2637/4468)\n",
      "Updating files:  60% (2681/4468)\n",
      "Updating files:  60% (2684/4468)\n",
      "Updating files:  61% (2726/4468)\n",
      "Updating files:  62% (2771/4468)\n",
      "Updating files:  62% (2808/4468)\n",
      "Updating files:  63% (2815/4468)\n",
      "Updating files:  64% (2860/4468)\n",
      "Updating files:  65% (2905/4468)\n",
      "Updating files:  66% (2949/4468)\n",
      "Updating files:  67% (2994/4468)\n",
      "Updating files:  68% (3039/4468)\n",
      "Updating files:  68% (3051/4468)\n",
      "Updating files:  69% (3083/4468)\n",
      "Updating files:  70% (3128/4468)\n",
      "Updating files:  71% (3173/4468)\n",
      "Updating files:  72% (3217/4468)\n",
      "Updating files:  73% (3262/4468)\n",
      "Updating files:  73% (3292/4468)\n",
      "Updating files:  74% (3307/4468)\n",
      "Updating files:  74% (3311/4468)\n",
      "Updating files:  74% (3340/4468)\n",
      "Updating files:  74% (3346/4468)\n",
      "Updating files:  75% (3351/4468)\n",
      "Updating files:  75% (3386/4468)\n",
      "Updating files:  76% (3396/4468)\n",
      "Updating files:  76% (3418/4468)\n",
      "Updating files:  77% (3441/4468)\n",
      "Updating files:  78% (3486/4468)\n",
      "Updating files:  79% (3530/4468)\n",
      "Updating files:  80% (3575/4468)\n",
      "Updating files:  81% (3620/4468)\n",
      "Updating files:  81% (3641/4468)\n",
      "Updating files:  82% (3664/4468)\n",
      "Updating files:  83% (3709/4468)\n",
      "Updating files:  84% (3754/4468)\n",
      "Updating files:  84% (3775/4468)\n",
      "Updating files:  84% (3777/4468)\n",
      "Updating files:  85% (3798/4468)\n",
      "Updating files:  85% (3838/4468)\n",
      "Updating files:  85% (3841/4468)\n",
      "Updating files:  86% (3843/4468)\n",
      "Updating files:  86% (3855/4468)\n",
      "Updating files:  87% (3888/4468)\n",
      "Updating files:  88% (3932/4468)\n",
      "Updating files:  89% (3977/4468)\n",
      "Updating files:  90% (4022/4468)\n",
      "Updating files:  91% (4066/4468)\n",
      "Updating files:  92% (4111/4468)\n",
      "Updating files:  93% (4156/4468)\n",
      "Updating files:  94% (4200/4468)\n",
      "Updating files:  95% (4245/4468)\n",
      "Updating files:  95% (4250/4468)\n",
      "Updating files:  96% (4290/4468)\n",
      "Updating files:  97% (4334/4468)\n",
      "Updating files:  98% (4379/4468)\n",
      "Updating files:  99% (4424/4468)\n",
      "Updating files: 100% (4468/4468)\n",
      "Updating files: 100% (4468/4468), done.\n"
     ]
    }
   ],
   "source": [
    "# We bring over our data\n",
    "!git clone https://github.com/varunjain3/EigenFaces.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "pqXUBrr5j2Tf"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'cp' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Copying our positive images to the training repo\n",
    "!cp -r /content/EigenFaces/data/pos/* /content/opencv-haar-classifier-training/positive_images/\n",
    "\n",
    "# Copying negative images\n",
    "!cp -r /content/EigenFaces/data/neg/* /content/opencv-haar-classifier-training/negative_images/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "X8Z5fgZ3ks7-",
    "outputId": "0791ae86-dd03-4133-d146-22559ee19890"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "The system cannot find the path specified.\n"
     ]
    }
   ],
   "source": [
    "# Building Opencv\n",
    "!wget http://downloads.sourceforge.net/project/opencvlibrary/opencv-unix/2.4.9/opencv-2.4.9.zip\n",
    "!unzip opencv-2.4.9.zip >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "mTPgbIrdlA7T",
    "outputId": "b4f86419-32cd-4715-8731-b5cd4ada02fb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SilC\\A hybrid EigenFace and Viola Jones algorithm\\EigenFaces-master\\opencv-haar-classifier-training\n"
     ]
    }
   ],
   "source": [
    "%cd \"opencv-haar-classifier-training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "GbDy3OJgk28X"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Access denied - ./POSITIVE_IMAGES\n",
      "File not found - -INAME\n"
     ]
    }
   ],
   "source": [
    "# Making positive labels\n",
    "!find ./positive_images -iname \"*.jpg\" > positives.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Vh7J3RWrk_Mn"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Access denied - ./NEGATIVE_IMAGES\n",
      "File not found - -INAME\n"
     ]
    }
   ],
   "source": [
    "# Making negative labels\n",
    "!find ./negative_images -iname \"*.jpg\" > negatives.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "6j4xbTfElZlH"
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (3277867665.py, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"C:\\Users\\SilC\\AppData\\Local\\Temp\\ipykernel_10924\\3277867665.py\"\u001b[1;36m, line \u001b[1;32m2\u001b[0m\n\u001b[1;33m    get_ipython().system('perl bin/createsamples.pl positives.txt negatives.txt samples 1000    \"opencv_createsamples -bgcolor 0 -bgthresh 0 -maxxangle 1.1    -maxyangle 1.1 maxzangle 0.5 -maxidev 40 -w 40 -h 40\" >/dev/null')\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# Creating .vec file\n",
    " !perl bin/createsamples.pl positives.txt negatives.txt samples 1000\\\n",
    "   \"opencv_createsamples -bgcolor 0 -bgthresh 0 -maxxangle 1.1\\\n",
    "   -maxyangle 1.1 maxzangle 0.5 -maxidev 40 -w 40 -h 40\" >/dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "jIEXCYbinNOZ",
    "outputId": "940d1fc9-1afd-473f-b040-ce55128fcbbe"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%%writefile` not found.\n"
     ]
    }
   ],
   "source": [
    "# Change due to python3, orignal file was for python2\n",
    "\n",
    "%%writefile /content/opencv-haar-classifier-training/tools/mergevec.py\n",
    "\n",
    "###############################################################################\n",
    "# Copyright (c) 2014, Blake Wulfe\n",
    "#\n",
    "# Permission is hereby granted, free of charge, to any person obtaining a copy\n",
    "# of this software and associated documentation files (the \"Software\"), to deal\n",
    "# in the Software without restriction, including without limitation the rights\n",
    "# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
    "# copies of the Software, and to permit persons to whom the Software is\n",
    "# furnished to do so, subject to the following conditions:\n",
    "#\n",
    "# The above copyright notice and this permission notice shall be included in\n",
    "# all copies or substantial portions of the Software.\n",
    "#\n",
    "# THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
    "# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
    "# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
    "# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
    "# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
    "# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN\n",
    "# THE SOFTWARE.\n",
    "###############################################################################\n",
    "\n",
    "\"\"\"\n",
    "File: mergevec.py\n",
    "Author: blake.w.wulfe@gmail.com\n",
    "Date: 6/13/2014\n",
    "File Description:\n",
    "\n",
    "\tThis file contains a function that merges .vec files called \"merge_vec_files\".\n",
    "\tI made it as a replacement for mergevec.cpp (created by Naotoshi Seo.\n",
    "\tSee: http://note.sonots.com/SciSoftware/haartraining/mergevec.cpp.html)\n",
    "\tin order to avoid recompiling openCV with mergevec.cpp.\n",
    "\n",
    "\tTo use the function:\n",
    "\t(1) Place all .vec files to be merged in a single directory (vec_directory).\n",
    "\t(2) Navigate to this file in your CLI (terminal or cmd) and type \"python mergevec.py -v your_vec_directory -o your_output_filename\".\n",
    "\n",
    "\t\tThe first argument (-v) is the name of the directory containing the .vec files\n",
    "\t\tThe second argument (-o) is the name of the output file\n",
    "\n",
    "\tTo test the output of the function:\n",
    "\t(1) Install openCV.\n",
    "\t(2) Navigate to the output file in your CLI (terminal or cmd).\n",
    "\t(2) Type \"opencv_createsamples -w img_width -h img_height -vec output_filename\".\n",
    "\t\tThis should show the .vec files in sequence.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import sys\n",
    "import glob\n",
    "import struct\n",
    "import argparse\n",
    "import traceback\n",
    "\n",
    "\n",
    "def exception_response(e):\n",
    "\texc_type, exc_value, exc_traceback = sys.exc_info()\n",
    "\tlines = traceback.format_exception(exc_type, exc_value, exc_traceback)\n",
    "\tfor line in lines:\n",
    "\t\tprint(line)\n",
    "\n",
    "def get_args():\n",
    "\tparser = argparse.ArgumentParser()\n",
    "\tparser.add_argument('-v', dest='vec_directory')\n",
    "\tparser.add_argument('-o', dest='output_filename')\n",
    "\targs = parser.parse_args()\n",
    "\treturn (args.vec_directory, args.output_filename)\n",
    "\n",
    "def merge_vec_files(vec_directory, output_vec_file):\n",
    "\t\"\"\"\n",
    "\tIterates throught the .vec files in a directory and combines them.\n",
    "\n",
    "\t(1) Iterates through files getting a count of the total images in the .vec files\n",
    "\t(2) checks that the image sizes in all files are the same\n",
    "\n",
    "\tThe format of a .vec file is:\n",
    "\n",
    "\t4 bytes denoting number of total images (int)\n",
    "\t4 bytes denoting size of images (int)\n",
    "\t2 bytes denoting min value (short)\n",
    "\t2 bytes denoting max value (short)\n",
    "\n",
    "\tex: \t6400 0000 4605 0000 0000 0000\n",
    "\n",
    "\t\thex\t\t6400 0000  \t4605 0000 \t\t0000 \t\t0000\n",
    "\t\t\t   \t# images  \tsize of h * w\t\tmin\t\tmax\n",
    "\t\tdec\t    \t100     \t1350\t\t\t0 \t\t0\n",
    "\n",
    "\t:type vec_directory: string\n",
    "\t:param vec_directory: Name of the directory containing .vec files to be combined.\n",
    "\t\t\t\tDo not end with slash. Ex: '/Users/username/Documents/vec_files'\n",
    "\n",
    "\t:type output_vec_file: string\n",
    "\t:param output_vec_file: Name of aggregate .vec file for output.\n",
    "\t\tEx: '/Users/username/Documents/aggregate_vec_file.vec'\n",
    "\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Check that the .vec directory does not end in '/' and if it does, remove it.\n",
    "\tif vec_directory.endswith('/'):\n",
    "\t\tvec_directory = vec_directory[:-1]\n",
    "\t# Get .vec files\n",
    "\tfiles = glob.glob('{0}/*.vec'.format(vec_directory))\n",
    "\n",
    "\t# Check to make sure there are .vec files in the directory\n",
    "\tif len(files) <= 0:\n",
    "\t\tprint('Vec files to be mereged could not be found from directory: {0}'.format(vec_directory))\n",
    "\t\tsys.exit(1)\n",
    "\t# Check to make sure there are more than one .vec files\n",
    "\tif len(files) == 1:\n",
    "\t\tprint('Only 1 vec file was found in directory: {0}. Cannot merge a single file.'.format(vec_directory))\n",
    "\t\tsys.exit(1)\n",
    "\n",
    "\n",
    "\t# Get the value for the first image size\n",
    "\tprev_image_size = 0\n",
    "\ttry:\n",
    "\t\twith open(files[0], 'rb') as vecfile:\n",
    "\t\t\tcontent = b''.join((line) for line in vecfile.readlines())\n",
    "\t\t\tval = struct.unpack('<iihh', content[:12])\n",
    "\t\t\tprev_image_size = val[1]\n",
    "\texcept IOError as e:\n",
    "\t\tprint('An IO error occured while processing the file: {0}'.format(f))\n",
    "\t\texception_response(e)\n",
    "\n",
    "\n",
    "\t# Get the total number of images\n",
    "\ttotal_num_images = 0\n",
    "\tfor f in files:\n",
    "\t\ttry:\n",
    "\t\t\twith open(f, 'rb') as vecfile:\n",
    "\t\t\t\tcontent = b''.join((line) for line in vecfile.readlines())\n",
    "\t\t\t\tval = struct.unpack('<iihh', content[:12])\n",
    "\t\t\t\tnum_images = val[0]\n",
    "\t\t\t\timage_size = val[1]\n",
    "\t\t\t\tif image_size != prev_image_size:\n",
    "\t\t\t\t\terr_msg = \"\"\"The image sizes in the .vec files differ. These values must be the same. \\n The image size of file {0}: {1}\\n\n",
    "\t\t\t\t\t\tThe image size of previous files: {0}\"\"\".format(f, image_size, prev_image_size)\n",
    "\t\t\t\t\tsys.exit(err_msg)\n",
    "\n",
    "\t\t\t\ttotal_num_images += num_images\n",
    "\t\texcept IOError as e:\n",
    "\t\t\tprint('An IO error occured while processing the file: {0}'.format(f))\n",
    "\t\t\texception_response(e)\n",
    "\n",
    "\n",
    "\t# Iterate through the .vec files, writing their data (not the header) to the output file\n",
    "\t# '<iihh' means 'little endian, int, int, short, short'\n",
    "\theader = struct.pack('<iihh', total_num_images, image_size, 0, 0)\n",
    "\ttry:\n",
    "\t\twith open(output_vec_file, 'wb') as outputfile:\n",
    "\t\t\toutputfile.write(header)\n",
    "\n",
    "\t\t\tfor f in files:\n",
    "\t\t\t\twith open(f, 'rb') as vecfile:\n",
    "\t\t\t\t\tcontent = b''.join((line) for line in vecfile.readlines())\n",
    "\t\t\t\t\toutputfile.write(bytearray(content[12:]))\n",
    "\texcept Exception as e:\n",
    "\t\texception_response(e)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\tvec_directory, output_filename = get_args()\n",
    "\tif not vec_directory:\n",
    "\t\tsys.exit('mergvec requires a directory of vec files. Call mergevec.py with -v /your_vec_directory')\n",
    "\tif not output_filename:\n",
    "\t\tsys.exit('mergevec requires an output filename. Call mergevec.py with -o your_output_filename')\n",
    "\n",
    "\tmerge_vec_files(vec_directory, output_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "ZxQix2-1llWV"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "python: can't open file 'C:\\Users\\SilC\\A hybrid EigenFace and Viola Jones algorithm\\EigenFaces-master\\tools\\mergevec.py': [Errno 2] No such file or directory\n"
     ]
    }
   ],
   "source": [
    "# Calling the file updated above\n",
    "!python ./tools/mergevec.py -v samples/ -o samples.vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "h9qV_zOZnXMr",
    "outputId": "bc2cfec1-65f4-4e46-9c34-ce0bd0961159"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "A subdirectory or file classifier already exists.\n",
      "'opencv_traincascade' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "# Training the classifier\n",
    "!rm -r classifier\n",
    "!mkdir classifier\n",
    "\n",
    "!opencv_traincascade -data classifier -vec samples.vec -bg negatives.txt\\\n",
    "   -numStages 10 -minHitRate 0.999 -maxFalseAlarmRate 0.5 -numPos 300\\\n",
    "   -numNeg 550 -w 40 -h 40 -mode ALL -precalcValBufSize 1024\\\n",
    "   -precalcIdxBufSize 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyM7bhtkTwVC/SzRBgLurTWS",
   "include_colab_link": true,
   "mount_file_id": "1B6j8ma3SPqOihw2SoEMMcYV08in-PDjB",
   "name": "Train_cascade.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
